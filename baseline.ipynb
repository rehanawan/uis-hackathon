{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from prophet import Prophet\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta, datetime\n",
    "import random\n",
    "\n",
    "def load_and_clean_data(file_path):\n",
    "    data = pd.read_excel(file_path, parse_dates=['DateAndHour'])\n",
    "    data['Hour'] = data['DateAndHour'].dt.hour\n",
    "    data['DayOfWeek'] = data['DateAndHour'].dt.dayofweek\n",
    "    data['Month'] = data['DateAndHour'].dt.month\n",
    "    data = data.dropna(subset=['Temperature', 'Load_data'])\n",
    "    return data\n",
    "\n",
    "def add_lag_and_rolling_features(data, lags=[1, 24, 168], window=3):\n",
    "    for lag in lags:\n",
    "        data[f'Load_data_lag_{lag}'] = data['Load_data'].shift(lag)\n",
    "        data[f'Temperature_lag_{lag}'] = data['Temperature'].shift(lag)\n",
    "    \n",
    "    data[f'Load_data_rolling_{window}'] = data['Load_data'].rolling(window=window).mean()\n",
    "    data[f'Load_data_rolling_std_{window}'] = data['Load_data'].rolling(window=window).std()\n",
    "    data['Temperature_change'] = data['Temperature'].diff()\n",
    "    \n",
    "    data['Temperature_bins'] = pd.cut(data['Temperature'], bins=[-np.inf, 0, 15, np.inf], labels=['cold', 'moderate', 'hot'])\n",
    "    data = pd.get_dummies(data, columns=['Temperature_bins'], drop_first=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def prepare_data_for_date(data, target_date, features):\n",
    "    if isinstance(target_date, str):\n",
    "        target_date = datetime.strptime(target_date, '%d/%m/%Y').date()\n",
    "    \n",
    "    if target_date in data['DateAndHour'].dt.date.values:\n",
    "        target_data = data[data['DateAndHour'].dt.date == target_date].copy()\n",
    "    else:\n",
    "        # Create a DataFrame for the future date\n",
    "        target_data = pd.DataFrame({\n",
    "            'DateAndHour': pd.date_range(start=target_date, periods=24, freq='H'),\n",
    "            'Hour': range(24),\n",
    "            'DayOfWeek': target_date.weekday(),\n",
    "            'Month': target_date.month\n",
    "        })\n",
    "        # Use average temperature from historical data for the same month\n",
    "        avg_temp_by_hour = data[data['DateAndHour'].dt.month == target_date.month].groupby(data['DateAndHour'].dt.hour)['Temperature'].mean()\n",
    "        target_data['Temperature'] = target_data['Hour'].map(avg_temp_by_hour)\n",
    "    \n",
    "    for feature in features:\n",
    "        if feature not in target_data.columns:\n",
    "            target_data[feature] = 0\n",
    "    \n",
    "    return target_data\n",
    "\n",
    "def debug_data(data, name):\n",
    "    print(f\"\\nDebugging {name}:\")\n",
    "    print(f\"Type: {type(data)}\")\n",
    "    print(f\"Shape: {data.shape}\")\n",
    "    \n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        print(\"Columns:\")\n",
    "        print(data.columns)\n",
    "        print(\"\\nFirst few rows:\")\n",
    "        print(data.head())\n",
    "        print(\"\\nData types:\")\n",
    "        print(data.dtypes)\n",
    "        print(\"\\nMissing values:\")\n",
    "        print(data.isnull().sum())\n",
    "    elif isinstance(data, pd.Series):\n",
    "        print(\"Name:\", data.name)\n",
    "        print(\"\\nFirst few values:\")\n",
    "        print(data.head())\n",
    "        print(\"\\nData type:\")\n",
    "        print(data.dtype)\n",
    "        print(\"\\nMissing values:\")\n",
    "        print(data.isnull().sum())\n",
    "    \n",
    "    print(\"\\nSummary statistics:\")\n",
    "    print(data.describe())\n",
    "\n",
    "def xgboost_model(X_train, y_train, X_future):\n",
    "    model = xgb.XGBRegressor(n_estimators=200, learning_rate=0.05, max_depth=6, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.predict(X_future)\n",
    "\n",
    "def prophet_model(data_train, future):\n",
    "    model = Prophet(daily_seasonality=True)\n",
    "    model.add_regressor('Temperature')\n",
    "    model.fit(data_train)\n",
    "    forecast = model.predict(future)\n",
    "    return forecast['yhat'].values\n",
    "\n",
    "def arima_model(y_train, n_future):\n",
    "    model = ARIMA(y_train, order=(5,1,2))\n",
    "    results = model.fit()\n",
    "    return results.forecast(steps=n_future)\n",
    "\n",
    "def random_forest_model(X_train, y_train, X_future):\n",
    "    model = RandomForestRegressor(n_estimators=200, max_depth=15, min_samples_split=5, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.predict(X_future)\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    non_zero = (y_true != 0)\n",
    "    return np.mean(np.abs((y_true[non_zero] - y_pred[non_zero]) / y_true[non_zero])) * 100\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and prepare data\n",
    "    data = load_and_clean_data('Hackathon_Data_Cleaned.xlsx')\n",
    "    \n",
    "    # Define lags\n",
    "    lags = [1, 24, 168]\n",
    "    \n",
    "    data = add_lag_and_rolling_features(data, lags=lags, window=3)\n",
    "\n",
    "    debug_data(data, \"Historical Data\")\n",
    "\n",
    "    # Define features\n",
    "    features = ['Hour', 'DayOfWeek', 'Month', 'Temperature', 'Temperature_change',\n",
    "                'Load_data_lag_1', 'Load_data_lag_24', 'Load_data_lag_168', \n",
    "                'Temperature_lag_1', 'Temperature_lag_24', 'Temperature_lag_168',\n",
    "                'Load_data_rolling_3', 'Load_data_rolling_std_3',\n",
    "                'Temperature_bins_moderate', 'Temperature_bins_hot']\n",
    "\n",
    "    # Prepare training data\n",
    "    X_train = data[features].dropna()\n",
    "    y_train = data['Load_data'].loc[X_train.index]\n",
    "\n",
    "#     debug_data(X_train, \"Training Features\")\n",
    "#     debug_data(y_train, \"Training Target\")\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "\n",
    "    # Select random dates for prediction (excluding the last week to ensure we have actual data for comparison)\n",
    "    max_date = data['DateAndHour'].dt.date.max() - timedelta(days=7)\n",
    "    min_date = data['DateAndHour'].dt.date.min() + timedelta(days=max(lags))\n",
    "    available_dates = pd.date_range(start=min_date, end=max_date).date\n",
    "    random_dates = random.sample(list(available_dates), 2)  # Select 5 random dates\n",
    "\n",
    "    # Add manual dates\n",
    "    manual_dates = ['26/03/2024', '30/03/2024']\n",
    "    all_dates = random_dates + manual_dates\n",
    "\n",
    "    all_predictions = []\n",
    "    all_actuals = []\n",
    "\n",
    "    for target_date in all_dates:\n",
    "        print(f\"\\nPredicting for date: {target_date}\")\n",
    "        \n",
    "        # Prepare data for the target date\n",
    "        target_data = prepare_data_for_date(data, target_date, features + ['DateAndHour'])\n",
    "        X_target_scaled = pd.DataFrame(scaler.transform(target_data[features]), columns=features, index=target_data.index)\n",
    "        \n",
    "        # Generate predictions\n",
    "        xgb_pred = xgboost_model(X_train_scaled, y_train, X_target_scaled)\n",
    "        \n",
    "        prophet_data_train = data[['DateAndHour', 'Load_data', 'Temperature']].rename(columns={'DateAndHour': 'ds', 'Load_data': 'y'})\n",
    "        prophet_target = target_data[['DateAndHour', 'Temperature']].rename(columns={'DateAndHour': 'ds'})\n",
    "        prophet_pred = prophet_model(prophet_data_train, prophet_target)\n",
    "        \n",
    "        rf_pred = random_forest_model(X_train_scaled, y_train, X_target_scaled)\n",
    "        arima_pred = arima_model(y_train, len(target_data))\n",
    "        \n",
    "        # Ensemble prediction\n",
    "        final_pred = np.nanmean([xgb_pred, prophet_pred, rf_pred, arima_pred], axis=0)\n",
    "        \n",
    "        # For random dates, calculate MAPE\n",
    "#         if target_date not in manual_dates:\n",
    "        actual_values = data[data['DateAndHour'].dt.date == target_date]['Load_data'].values\n",
    "        all_predictions.extend(final_pred)\n",
    "        all_actuals.extend(actual_values)\n",
    "        mape = mean_absolute_percentage_error(actual_values, final_pred)\n",
    "        print(f\"MAPE for {target_date}: {mape:.2f}%\")\n",
    "#         else:\n",
    "#             print(f\"Predictions for {target_date}:\")\n",
    "#             for hour, pred in enumerate(final_pred):\n",
    "#                 print(f\"Hour {hour}: {pred:.2f}\")\n",
    "        \n",
    "        # Plotting\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(range(24), final_pred, label='Predicted Load', marker='x')\n",
    "        if target_date not in manual_dates:\n",
    "            plt.plot(range(24), actual_values, label='Actual Load', marker='o')\n",
    "        plt.title(f'Load Prediction for {target_date}')\n",
    "        plt.xlabel('Hour')\n",
    "        plt.ylabel('Load')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f'load_prediction_{target_date}.png')\n",
    "        plt.close()\n",
    "\n",
    "    # Calculate overall MAPE for random dates\n",
    "    if all_actuals:\n",
    "        overall_mape = mean_absolute_percentage_error(all_actuals, all_predictions)\n",
    "        print(f\"\\nOverall MAPE for random dates: {overall_mape:.2f}%\")\n",
    "\n",
    "    print(\"\\nPrediction plots saved as 'load_prediction_<date>.png'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
